import numpy as np
import matplotlib.pyplot as plt
plt.style.use('seaborn')





## Simple sigmoid function
sigmoid = lambda pi: 1 / (1+np.exp(-pi))
pi = np.linspace(-4, 4, 100)
plt.plot(pi, sigmoid(pi))
plt.xlabel('$\pi$', fontsize=28)
plt.ylabel("sigmoid value", fontsize=28)
plt.savefig("sigmoid.png");





# Generate synthetic data
np.random.seed(42)
num_samples = 100
num_features = 2
X = np.random.rand(num_samples, num_features)
y = np.random.randint(0, 2, num_samples)

# Sigmoid function
def sigmoid(z):
    return 1 / (1 + np.exp(-z))

# Initialize weights and bias
beta = np.random.randn(num_features)
b = np.random.randn()


z = np.dot(X, beta) + b
z


y_pred = sigmoid(z)
y_pred





# Training loop
learning_rate = 0.1
num_epochs = 1000

for epoch in range(num_epochs):
    z = np.dot(X, beta) + b
    y_pred = sigmoid(z)
    
    # Compute gradients
    dBeta = np.dot(X.T, (y_pred - y)) / num_samples
    db = np.sum(y_pred - y) / num_samples
    
    # Update weights and bias
    beta -= learning_rate * dBeta
    b -= learning_rate * db

# Predictions
probabilities = sigmoid(np.dot(X, beta) + b)
predictions = (probabilities > 0.5).astype(int)





np.round(probabilities, 2)





predictions



