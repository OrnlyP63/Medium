


import numpy as np
from sklearn import datasets
from sklearn import preprocessing
from sklearn import model_selection


features, targets = datasets.load_breast_cancer(return_X_y=True)


features.shape


x_train, x_test, y_train, y_test = model_selection.train_test_split(features, targets, test_size=0.2, random_state=0)


n_features = x_train.shape[-1]
n_features


# Input features are centered and scaled to unit variance:
feature_encoder = preprocessing.StandardScaler()
x_train = feature_encoder.fit_transform(x_train)
x_test = feature_encoder.transform(x_test)


x_train.shape[0], x_test.shape[0]


# number of neurons per layer, the last element must be 1
n_neurons = np.array([100, 10, 1])
n_branches = 20  # number of dendritic brancher per neuron


n_neurons


n_inputs = np.hstack([n_features + 1, n_neurons[:-1] + 1])


n_inputs


dgn_weights = [np.zeros((n_neuron, n_branches, n_input)) for n_neuron, n_input in zip(n_neurons, n_inputs)]


dgn_weights[0].shape


dgn_weights[1].shape


dgn_weights[2].shape


dgn_hyperplanes = [np.random.normal(0, 1, size=(n_neuron, n_branches, n_features + 1)) for n_neuron in n_neurons]


dgn_hyperplanes[0].shape


dgn_hyperplanes = [
    h_ / np.linalg.norm(h_[:, :, :-1], axis=(1, 2))[:, None, None]
    for h_ in dgn_hyperplanes]


dgn_hyperplanes[0].shape


i = 0
for i, x_i in enumerate(x_train):
    if i == 2:
        break

for w, h in zip(dgn_weights, dgn_hyperplanes):
    break


target = 1


side_info = np.hstack([1., x_i])
side_info.shape


r_in = np.hstack([1., x_i])
r_in


h.shape


side_info.shape


h.dot(side_info).shape


gate_values = np.heaviside(h.dot(side_info), 0).astype(bool)
gate_values


w.shape


gate_values.shape


effective_weights = gate_values.dot(w).sum(axis=1)
effective_weights


gate_values.dot(w).shape


effective_weights.shape


r_in.shape


r_out = effective_weights.dot(r_in)


r_out.shape


r_out[:, None].shape


r_in[None].shape


grad = (r_out[:, None] - target) * r_in[None]
grad


grad.shape


learning_rate = 0.001


gate_values[:, :, None].shape


gate_values.shape


grad[:, None].shape


a = gate_values[:, :, None] * grad[:, None]


a.shape


w.shape


w -= learning_rate * gate_values[:, :, None] * grad[:, None]


r_out.shape



