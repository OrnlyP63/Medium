import torch





x = torch.normal(0, 1, [31])


x.shape





h = torch.normal(0, 1, [100, 20, 31])


g = torch.matmul(h, x)
g = torch.heaviside(g, torch.tensor(0.))





g.shape





w = torch.normal(0, 1, [100, 20, 31]) 





ew = torch.matmul(g, w)


ew.shape


ew_sum = ew.sum(dim=1)


ew_sum.shape





r_output = torch.matmul(ew_sum, x)


r_output.shape


target = 1.


grad = (r_output[:, None] - target) * x[None]


grad.shape


(r_output[:, None] - target).shape


learning_rate = 0.01


w -= learning_rate * g[:, :, None] * grad[:, None]


w.shape





x = torch.normal(0, 1, [31, 455])


x.shape


g = torch.matmul(h, x)


g.shape


r = torch.einsum('ijk,ijl->ilk', g, w)


r.shape


res = torch.einsum('ijk,jk->ik', r, x)


res.shape


target = torch.ones([1, 455])


d = (res - target)
d.shape


x.shape


d[:, 0].shape


x[:, 0].shape


d = torch.normal(0, 1, [100, 455])
x = torch.normal(0, 1, [31, 455])
g = torch.normal(0, 1, [100, 20])

res = []
for i in range(d.shape[1]):
    x_i = x[:, i]
    d_i = d[:, i]
    grad = d_i[:, None] * x_i[None]
    r = g[:, :, None] * grad[:, None]
    
    res.append(r)
    
res = torch.stack(res) #.mean(dim=0)


res.shape


res_vec = torch.einsum('bi,ai,bc->ibca', d, x, g).mean(dim=0)


res_vec.shape


res.mean(dim=0).shape


res.shape


w.shape


aa = w - res


aa.shape



