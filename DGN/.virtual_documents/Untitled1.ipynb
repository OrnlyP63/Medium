import numpy as np
from sklearn import datasets
from sklearn import preprocessing
from sklearn import model_selection


features, targets = datasets.load_breast_cancer(return_X_y=True)


features.shape


x_train, x_test, y_train, y_test = model_selection.train_test_split(features, targets, test_size=0.2, random_state=0)


n_features = x_train.shape[-1]
n_features


# Input features are centered and scaled to unit variance:
feature_encoder = preprocessing.StandardScaler()
x_train = feature_encoder.fit_transform(x_train)
x_test = feature_encoder.transform(x_test)


x_train.shape[0], x_test.shape[0]


# number of neurons per layer, the last element must be 1
n_neurons = np.array([100, 10, 1])
n_branches = 20  # number of dendritic brancher per neuron


n_neurons





import torch.nn as nn
import torch


x = np.hstack([np.ones((x_train.shape[0], 1)), x_train])
x = torch.FloatTensor(x)


x.shape


h = torch.normal(0, 1, [10, 20, 30 + 1])
w = torch.zeros([10, 20, 30 + 1])
# h[:, None, None].shape

# torch.linalg.norm(h[:, :, :-1], axis=(1, 2))

h = h / torch.linalg.norm(h[:, :, :-1], axis=(1, 2))[:, None, None]


h.shape


w.shape


a = torch.matmul(h, x.T)


a.shape


gate_values = np.heaviside(a, 0)


gate_values.shape


w.shape


effective_weights = torch.tensordot(gate_values, w, dims=([1], [1])).sum(dim=2)


effective_weights.shape


x.shape


torch.matmul(effective_weights, x.T).shape


# Define the 3D tensor A with dimensions (B, M, N)
B, M, N = 2, 3, 4
A = torch.randn(B, M, N)

# Define the 3D tensor B with dimensions (B, N, P)
N, P = 4, 5
B = torch.randn(B, N, P)

# Perform the batch-wise matrix multiplication
result = torch.matmul(A, B)

# result will have dimensions (B, M, P)
print(result.shape)  # Should output: torch.Size([2, 3, 5])
print(result)



