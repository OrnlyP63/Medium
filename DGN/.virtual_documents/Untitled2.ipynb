import torch





x = torch.normal(0, 1, [31])


x.shape





h = torch.normal(0, 1, [100, 20, 31])


g = torch.matmul(h, x)
g = torch.heaviside(g, torch.tensor(0.))





g.shape





w = torch.normal(0, 1, [100, 20, 31]) 





ew = torch.matmul(g, w)


ew.shape


ew_sum = ew.sum(dim=1)


ew_sum.shape





r_output = torch.matmul(ew_sum, x)


r_output.shape


target = 1.


grad = (r_output[:, None] - target) * x[None]


grad.shape


(r_output[:, None] - target).shape


learning_rate = 0.01


w -= learning_rate * g[:, :, None] * grad[:, None]


w.shape





x = torch.normal(0, 1, [31, 455])


x.shape


g = torch.matmul(h, x)


g.shape


g[:, :, 0].shape


w.shape


a = torch.normal(0, 1, [100, 20, 455])
b = torch.normal(0, 1, [100, 20, 31])

res = []
for i in range(a.shape[2]):
    a_i = a[:, :, i]
    r = torch.matmul(a_i, b)
    res.append(r.sum(dim=1))

final_res = torch.stack(res)


final_res.shape


# Create random tensors
a = torch.normal(0, 1, [100, 20, 455])
b = torch.normal(0, 1, [100, 20, 31])

# Use torch.einsum to perform the batched matrix multiplication and summation
# 'ijk,ijl->ikl' means:
# i = batch dimension
# j = shared dimension for matrix multiplication
# k = output dimensions
# The resulting tensor will have dimensions (455, 100, 31)
res = torch.einsum('ijk,ijl->ikl', a, b).sum(dim=1)

# Transpose the result to match the desired final shape (455, 100)
final_res = res.transpose(0, 1)

print(final_res.shape)


torch.einsum('ijk,ijl->ikl', a, b).shape


ew = torch.tensordot(w, g, dims=([1], [1]))


ew.shape


ew_sum = ew.sum(dim=2)


ew_sum.shape


x.shape


ew_sum = torch.permute(ew_sum,[1, 2, 0])
ew_sum.shape


r = torch.tensordot(ew_sum, x, dims=([0, 1], [0, 1]))


r.shape


import torch
import torch.nn as nn

# Define a simple model
class SimpleModel(nn.Module):
    def __init__(self):
        super(SimpleModel, self).__init__()
        self.fc1 = nn.Linear(10, 5)
        self.fc2 = nn.Linear(5, 2)

    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# Instantiate the model
model = SimpleModel()

# Access the weights of all layers
for name, param in model.named_parameters():
    if 'weight' in name:
        print(f"Layer: {name}, Weight: {param}")




